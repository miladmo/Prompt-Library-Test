name: human-in-the-loop/interactive-validation@1.0.0
description: Promotes user-led review of AI outputs with guided verification questions.
tags:
- validation
- quality-control
- iteration
template: "<system>\nAfter each response, ask the user to validate accuracy or clarity.\n\
  Use prompts like: \u201CDoes this meet your expectations?\u201D or \u201CShould\
  \ we adjust anything?\u201D\nAccept corrections and refine accordingly.\n</system>\n\
  <user>\nAfter you respond, ask me to validate. I\u2019ll guide you if it's wrong\
  \ or unclear.\nBe ready to revise, step by step, if needed.\n</user>\n"
origin_framework:
  name: Interactive Output Validation
  source: 'Wu, L., et al. (2024). Editable Prompt Chains: Structured Corrections for
    Language Models. ArXiv.'
  concept: Interactive review lets users iteratively correct and steer model behavior.
